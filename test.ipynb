{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from pycocotools.coco import COCO\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<<unknown>>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.pkl\", 'rb') as fi:\n",
    "    vocabulary = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-52aa8623a898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "vocabulary.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.85s)\n",
      "creating index...\n",
      "index created!\n",
      "[1000/414113] Tokenized the captions.\n",
      "[2000/414113] Tokenized the captions.\n",
      "[3000/414113] Tokenized the captions.\n",
      "[4000/414113] Tokenized the captions.\n",
      "[5000/414113] Tokenized the captions.\n",
      "[6000/414113] Tokenized the captions.\n",
      "[7000/414113] Tokenized the captions.\n",
      "[8000/414113] Tokenized the captions.\n",
      "[9000/414113] Tokenized the captions.\n",
      "[10000/414113] Tokenized the captions.\n",
      "[11000/414113] Tokenized the captions.\n",
      "[12000/414113] Tokenized the captions.\n",
      "[13000/414113] Tokenized the captions.\n",
      "[14000/414113] Tokenized the captions.\n",
      "[15000/414113] Tokenized the captions.\n",
      "[16000/414113] Tokenized the captions.\n",
      "[17000/414113] Tokenized the captions.\n",
      "[18000/414113] Tokenized the captions.\n",
      "[19000/414113] Tokenized the captions.\n",
      "[20000/414113] Tokenized the captions.\n",
      "[21000/414113] Tokenized the captions.\n",
      "[22000/414113] Tokenized the captions.\n",
      "[23000/414113] Tokenized the captions.\n",
      "[24000/414113] Tokenized the captions.\n",
      "[25000/414113] Tokenized the captions.\n",
      "[26000/414113] Tokenized the captions.\n",
      "[27000/414113] Tokenized the captions.\n",
      "[28000/414113] Tokenized the captions.\n",
      "[29000/414113] Tokenized the captions.\n",
      "[30000/414113] Tokenized the captions.\n",
      "[31000/414113] Tokenized the captions.\n",
      "[32000/414113] Tokenized the captions.\n",
      "[33000/414113] Tokenized the captions.\n",
      "[34000/414113] Tokenized the captions.\n",
      "[35000/414113] Tokenized the captions.\n",
      "[36000/414113] Tokenized the captions.\n",
      "[37000/414113] Tokenized the captions.\n",
      "[38000/414113] Tokenized the captions.\n",
      "[39000/414113] Tokenized the captions.\n",
      "[40000/414113] Tokenized the captions.\n",
      "[41000/414113] Tokenized the captions.\n",
      "[42000/414113] Tokenized the captions.\n",
      "[43000/414113] Tokenized the captions.\n",
      "[44000/414113] Tokenized the captions.\n",
      "[45000/414113] Tokenized the captions.\n",
      "[46000/414113] Tokenized the captions.\n",
      "[47000/414113] Tokenized the captions.\n",
      "[48000/414113] Tokenized the captions.\n",
      "[49000/414113] Tokenized the captions.\n",
      "[50000/414113] Tokenized the captions.\n",
      "[51000/414113] Tokenized the captions.\n",
      "[52000/414113] Tokenized the captions.\n",
      "[53000/414113] Tokenized the captions.\n",
      "[54000/414113] Tokenized the captions.\n",
      "[55000/414113] Tokenized the captions.\n",
      "[56000/414113] Tokenized the captions.\n",
      "[57000/414113] Tokenized the captions.\n",
      "[58000/414113] Tokenized the captions.\n",
      "[59000/414113] Tokenized the captions.\n",
      "[60000/414113] Tokenized the captions.\n",
      "[61000/414113] Tokenized the captions.\n",
      "[62000/414113] Tokenized the captions.\n",
      "[63000/414113] Tokenized the captions.\n",
      "[64000/414113] Tokenized the captions.\n",
      "[65000/414113] Tokenized the captions.\n",
      "[66000/414113] Tokenized the captions.\n",
      "[67000/414113] Tokenized the captions.\n",
      "[68000/414113] Tokenized the captions.\n",
      "[69000/414113] Tokenized the captions.\n",
      "[70000/414113] Tokenized the captions.\n",
      "[71000/414113] Tokenized the captions.\n",
      "[72000/414113] Tokenized the captions.\n",
      "[73000/414113] Tokenized the captions.\n",
      "[74000/414113] Tokenized the captions.\n",
      "[75000/414113] Tokenized the captions.\n",
      "[76000/414113] Tokenized the captions.\n",
      "[77000/414113] Tokenized the captions.\n",
      "[78000/414113] Tokenized the captions.\n",
      "[79000/414113] Tokenized the captions.\n",
      "[80000/414113] Tokenized the captions.\n",
      "[81000/414113] Tokenized the captions.\n",
      "[82000/414113] Tokenized the captions.\n",
      "[83000/414113] Tokenized the captions.\n",
      "[84000/414113] Tokenized the captions.\n",
      "[85000/414113] Tokenized the captions.\n",
      "[86000/414113] Tokenized the captions.\n",
      "[87000/414113] Tokenized the captions.\n",
      "[88000/414113] Tokenized the captions.\n",
      "[89000/414113] Tokenized the captions.\n",
      "[90000/414113] Tokenized the captions.\n",
      "[91000/414113] Tokenized the captions.\n",
      "[92000/414113] Tokenized the captions.\n",
      "[93000/414113] Tokenized the captions.\n",
      "[94000/414113] Tokenized the captions.\n",
      "[95000/414113] Tokenized the captions.\n",
      "[96000/414113] Tokenized the captions.\n",
      "[97000/414113] Tokenized the captions.\n",
      "[98000/414113] Tokenized the captions.\n",
      "[99000/414113] Tokenized the captions.\n",
      "[100000/414113] Tokenized the captions.\n",
      "[101000/414113] Tokenized the captions.\n",
      "[102000/414113] Tokenized the captions.\n",
      "[103000/414113] Tokenized the captions.\n",
      "[104000/414113] Tokenized the captions.\n",
      "[105000/414113] Tokenized the captions.\n",
      "[106000/414113] Tokenized the captions.\n",
      "[107000/414113] Tokenized the captions.\n",
      "[108000/414113] Tokenized the captions.\n",
      "[109000/414113] Tokenized the captions.\n",
      "[110000/414113] Tokenized the captions.\n",
      "[111000/414113] Tokenized the captions.\n",
      "[112000/414113] Tokenized the captions.\n",
      "[113000/414113] Tokenized the captions.\n",
      "[114000/414113] Tokenized the captions.\n",
      "[115000/414113] Tokenized the captions.\n",
      "[116000/414113] Tokenized the captions.\n",
      "[117000/414113] Tokenized the captions.\n",
      "[118000/414113] Tokenized the captions.\n",
      "[119000/414113] Tokenized the captions.\n",
      "[120000/414113] Tokenized the captions.\n",
      "[121000/414113] Tokenized the captions.\n",
      "[122000/414113] Tokenized the captions.\n",
      "[123000/414113] Tokenized the captions.\n",
      "[124000/414113] Tokenized the captions.\n",
      "[125000/414113] Tokenized the captions.\n",
      "[126000/414113] Tokenized the captions.\n",
      "[127000/414113] Tokenized the captions.\n",
      "[128000/414113] Tokenized the captions.\n",
      "[129000/414113] Tokenized the captions.\n",
      "[130000/414113] Tokenized the captions.\n",
      "[131000/414113] Tokenized the captions.\n",
      "[132000/414113] Tokenized the captions.\n",
      "[133000/414113] Tokenized the captions.\n",
      "[134000/414113] Tokenized the captions.\n",
      "[135000/414113] Tokenized the captions.\n",
      "[136000/414113] Tokenized the captions.\n",
      "[137000/414113] Tokenized the captions.\n",
      "[138000/414113] Tokenized the captions.\n",
      "[139000/414113] Tokenized the captions.\n",
      "[140000/414113] Tokenized the captions.\n",
      "[141000/414113] Tokenized the captions.\n",
      "[142000/414113] Tokenized the captions.\n",
      "[143000/414113] Tokenized the captions.\n",
      "[144000/414113] Tokenized the captions.\n",
      "[145000/414113] Tokenized the captions.\n",
      "[146000/414113] Tokenized the captions.\n",
      "[147000/414113] Tokenized the captions.\n",
      "[148000/414113] Tokenized the captions.\n",
      "[149000/414113] Tokenized the captions.\n",
      "[150000/414113] Tokenized the captions.\n",
      "[151000/414113] Tokenized the captions.\n",
      "[152000/414113] Tokenized the captions.\n",
      "[153000/414113] Tokenized the captions.\n",
      "[154000/414113] Tokenized the captions.\n",
      "[155000/414113] Tokenized the captions.\n",
      "[156000/414113] Tokenized the captions.\n",
      "[157000/414113] Tokenized the captions.\n",
      "[158000/414113] Tokenized the captions.\n",
      "[159000/414113] Tokenized the captions.\n",
      "[160000/414113] Tokenized the captions.\n",
      "[161000/414113] Tokenized the captions.\n",
      "[162000/414113] Tokenized the captions.\n",
      "[163000/414113] Tokenized the captions.\n",
      "[164000/414113] Tokenized the captions.\n",
      "[165000/414113] Tokenized the captions.\n",
      "[166000/414113] Tokenized the captions.\n",
      "[167000/414113] Tokenized the captions.\n",
      "[168000/414113] Tokenized the captions.\n",
      "[169000/414113] Tokenized the captions.\n",
      "[170000/414113] Tokenized the captions.\n",
      "[171000/414113] Tokenized the captions.\n",
      "[172000/414113] Tokenized the captions.\n",
      "[173000/414113] Tokenized the captions.\n",
      "[174000/414113] Tokenized the captions.\n",
      "[175000/414113] Tokenized the captions.\n",
      "[176000/414113] Tokenized the captions.\n",
      "[177000/414113] Tokenized the captions.\n",
      "[178000/414113] Tokenized the captions.\n",
      "[179000/414113] Tokenized the captions.\n",
      "[180000/414113] Tokenized the captions.\n",
      "[181000/414113] Tokenized the captions.\n",
      "[182000/414113] Tokenized the captions.\n",
      "[183000/414113] Tokenized the captions.\n",
      "[184000/414113] Tokenized the captions.\n",
      "[185000/414113] Tokenized the captions.\n",
      "[186000/414113] Tokenized the captions.\n",
      "[187000/414113] Tokenized the captions.\n",
      "[188000/414113] Tokenized the captions.\n",
      "[189000/414113] Tokenized the captions.\n",
      "[190000/414113] Tokenized the captions.\n",
      "[191000/414113] Tokenized the captions.\n",
      "[192000/414113] Tokenized the captions.\n",
      "[193000/414113] Tokenized the captions.\n",
      "[194000/414113] Tokenized the captions.\n",
      "[195000/414113] Tokenized the captions.\n",
      "[196000/414113] Tokenized the captions.\n",
      "[197000/414113] Tokenized the captions.\n",
      "[198000/414113] Tokenized the captions.\n",
      "[199000/414113] Tokenized the captions.\n",
      "[200000/414113] Tokenized the captions.\n",
      "[201000/414113] Tokenized the captions.\n",
      "[202000/414113] Tokenized the captions.\n",
      "[203000/414113] Tokenized the captions.\n",
      "[204000/414113] Tokenized the captions.\n",
      "[205000/414113] Tokenized the captions.\n",
      "[206000/414113] Tokenized the captions.\n",
      "[207000/414113] Tokenized the captions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208000/414113] Tokenized the captions.\n",
      "[209000/414113] Tokenized the captions.\n",
      "[210000/414113] Tokenized the captions.\n",
      "[211000/414113] Tokenized the captions.\n",
      "[212000/414113] Tokenized the captions.\n",
      "[213000/414113] Tokenized the captions.\n",
      "[214000/414113] Tokenized the captions.\n",
      "[215000/414113] Tokenized the captions.\n",
      "[216000/414113] Tokenized the captions.\n",
      "[217000/414113] Tokenized the captions.\n",
      "[218000/414113] Tokenized the captions.\n",
      "[219000/414113] Tokenized the captions.\n",
      "[220000/414113] Tokenized the captions.\n",
      "[221000/414113] Tokenized the captions.\n",
      "[222000/414113] Tokenized the captions.\n",
      "[223000/414113] Tokenized the captions.\n",
      "[224000/414113] Tokenized the captions.\n",
      "[225000/414113] Tokenized the captions.\n",
      "[226000/414113] Tokenized the captions.\n",
      "[227000/414113] Tokenized the captions.\n",
      "[228000/414113] Tokenized the captions.\n",
      "[229000/414113] Tokenized the captions.\n",
      "[230000/414113] Tokenized the captions.\n",
      "[231000/414113] Tokenized the captions.\n",
      "[232000/414113] Tokenized the captions.\n",
      "[233000/414113] Tokenized the captions.\n",
      "[234000/414113] Tokenized the captions.\n",
      "[235000/414113] Tokenized the captions.\n",
      "[236000/414113] Tokenized the captions.\n",
      "[237000/414113] Tokenized the captions.\n",
      "[238000/414113] Tokenized the captions.\n",
      "[239000/414113] Tokenized the captions.\n",
      "[240000/414113] Tokenized the captions.\n",
      "[241000/414113] Tokenized the captions.\n",
      "[242000/414113] Tokenized the captions.\n",
      "[243000/414113] Tokenized the captions.\n",
      "[244000/414113] Tokenized the captions.\n",
      "[245000/414113] Tokenized the captions.\n",
      "[246000/414113] Tokenized the captions.\n",
      "[247000/414113] Tokenized the captions.\n",
      "[248000/414113] Tokenized the captions.\n",
      "[249000/414113] Tokenized the captions.\n",
      "[250000/414113] Tokenized the captions.\n",
      "[251000/414113] Tokenized the captions.\n",
      "[252000/414113] Tokenized the captions.\n",
      "[253000/414113] Tokenized the captions.\n",
      "[254000/414113] Tokenized the captions.\n",
      "[255000/414113] Tokenized the captions.\n",
      "[256000/414113] Tokenized the captions.\n",
      "[257000/414113] Tokenized the captions.\n",
      "[258000/414113] Tokenized the captions.\n",
      "[259000/414113] Tokenized the captions.\n",
      "[260000/414113] Tokenized the captions.\n",
      "[261000/414113] Tokenized the captions.\n",
      "[262000/414113] Tokenized the captions.\n",
      "[263000/414113] Tokenized the captions.\n",
      "[264000/414113] Tokenized the captions.\n",
      "[265000/414113] Tokenized the captions.\n",
      "[266000/414113] Tokenized the captions.\n",
      "[267000/414113] Tokenized the captions.\n",
      "[268000/414113] Tokenized the captions.\n",
      "[269000/414113] Tokenized the captions.\n",
      "[270000/414113] Tokenized the captions.\n",
      "[271000/414113] Tokenized the captions.\n",
      "[272000/414113] Tokenized the captions.\n",
      "[273000/414113] Tokenized the captions.\n",
      "[274000/414113] Tokenized the captions.\n",
      "[275000/414113] Tokenized the captions.\n",
      "[276000/414113] Tokenized the captions.\n",
      "[277000/414113] Tokenized the captions.\n",
      "[278000/414113] Tokenized the captions.\n",
      "[279000/414113] Tokenized the captions.\n",
      "[280000/414113] Tokenized the captions.\n",
      "[281000/414113] Tokenized the captions.\n",
      "[282000/414113] Tokenized the captions.\n",
      "[283000/414113] Tokenized the captions.\n",
      "[284000/414113] Tokenized the captions.\n",
      "[285000/414113] Tokenized the captions.\n",
      "[286000/414113] Tokenized the captions.\n",
      "[287000/414113] Tokenized the captions.\n",
      "[288000/414113] Tokenized the captions.\n",
      "[289000/414113] Tokenized the captions.\n",
      "[290000/414113] Tokenized the captions.\n",
      "[291000/414113] Tokenized the captions.\n",
      "[292000/414113] Tokenized the captions.\n",
      "[293000/414113] Tokenized the captions.\n",
      "[294000/414113] Tokenized the captions.\n",
      "[295000/414113] Tokenized the captions.\n",
      "[296000/414113] Tokenized the captions.\n",
      "[297000/414113] Tokenized the captions.\n",
      "[298000/414113] Tokenized the captions.\n",
      "[299000/414113] Tokenized the captions.\n",
      "[300000/414113] Tokenized the captions.\n",
      "[301000/414113] Tokenized the captions.\n",
      "[302000/414113] Tokenized the captions.\n",
      "[303000/414113] Tokenized the captions.\n",
      "[304000/414113] Tokenized the captions.\n",
      "[305000/414113] Tokenized the captions.\n",
      "[306000/414113] Tokenized the captions.\n",
      "[307000/414113] Tokenized the captions.\n",
      "[308000/414113] Tokenized the captions.\n",
      "[309000/414113] Tokenized the captions.\n",
      "[310000/414113] Tokenized the captions.\n",
      "[311000/414113] Tokenized the captions.\n",
      "[312000/414113] Tokenized the captions.\n",
      "[313000/414113] Tokenized the captions.\n",
      "[314000/414113] Tokenized the captions.\n",
      "[315000/414113] Tokenized the captions.\n",
      "[316000/414113] Tokenized the captions.\n",
      "[317000/414113] Tokenized the captions.\n",
      "[318000/414113] Tokenized the captions.\n",
      "[319000/414113] Tokenized the captions.\n",
      "[320000/414113] Tokenized the captions.\n",
      "[321000/414113] Tokenized the captions.\n",
      "[322000/414113] Tokenized the captions.\n",
      "[323000/414113] Tokenized the captions.\n",
      "[324000/414113] Tokenized the captions.\n",
      "[325000/414113] Tokenized the captions.\n",
      "[326000/414113] Tokenized the captions.\n",
      "[327000/414113] Tokenized the captions.\n",
      "[328000/414113] Tokenized the captions.\n",
      "[329000/414113] Tokenized the captions.\n",
      "[330000/414113] Tokenized the captions.\n",
      "[331000/414113] Tokenized the captions.\n",
      "[332000/414113] Tokenized the captions.\n",
      "[333000/414113] Tokenized the captions.\n",
      "[334000/414113] Tokenized the captions.\n",
      "[335000/414113] Tokenized the captions.\n",
      "[336000/414113] Tokenized the captions.\n",
      "[337000/414113] Tokenized the captions.\n",
      "[338000/414113] Tokenized the captions.\n",
      "[339000/414113] Tokenized the captions.\n",
      "[340000/414113] Tokenized the captions.\n",
      "[341000/414113] Tokenized the captions.\n",
      "[342000/414113] Tokenized the captions.\n",
      "[343000/414113] Tokenized the captions.\n",
      "[344000/414113] Tokenized the captions.\n",
      "[345000/414113] Tokenized the captions.\n",
      "[346000/414113] Tokenized the captions.\n",
      "[347000/414113] Tokenized the captions.\n",
      "[348000/414113] Tokenized the captions.\n",
      "[349000/414113] Tokenized the captions.\n",
      "[350000/414113] Tokenized the captions.\n",
      "[351000/414113] Tokenized the captions.\n",
      "[352000/414113] Tokenized the captions.\n",
      "[353000/414113] Tokenized the captions.\n",
      "[354000/414113] Tokenized the captions.\n",
      "[355000/414113] Tokenized the captions.\n",
      "[356000/414113] Tokenized the captions.\n",
      "[357000/414113] Tokenized the captions.\n",
      "[358000/414113] Tokenized the captions.\n",
      "[359000/414113] Tokenized the captions.\n",
      "[360000/414113] Tokenized the captions.\n",
      "[361000/414113] Tokenized the captions.\n",
      "[362000/414113] Tokenized the captions.\n",
      "[363000/414113] Tokenized the captions.\n",
      "[364000/414113] Tokenized the captions.\n",
      "[365000/414113] Tokenized the captions.\n",
      "[366000/414113] Tokenized the captions.\n",
      "[367000/414113] Tokenized the captions.\n",
      "[368000/414113] Tokenized the captions.\n",
      "[369000/414113] Tokenized the captions.\n",
      "[370000/414113] Tokenized the captions.\n",
      "[371000/414113] Tokenized the captions.\n",
      "[372000/414113] Tokenized the captions.\n",
      "[373000/414113] Tokenized the captions.\n",
      "[374000/414113] Tokenized the captions.\n",
      "[375000/414113] Tokenized the captions.\n",
      "[376000/414113] Tokenized the captions.\n",
      "[377000/414113] Tokenized the captions.\n",
      "[378000/414113] Tokenized the captions.\n",
      "[379000/414113] Tokenized the captions.\n",
      "[380000/414113] Tokenized the captions.\n",
      "[381000/414113] Tokenized the captions.\n",
      "[382000/414113] Tokenized the captions.\n",
      "[383000/414113] Tokenized the captions.\n",
      "[384000/414113] Tokenized the captions.\n",
      "[385000/414113] Tokenized the captions.\n",
      "[386000/414113] Tokenized the captions.\n",
      "[387000/414113] Tokenized the captions.\n",
      "[388000/414113] Tokenized the captions.\n",
      "[389000/414113] Tokenized the captions.\n",
      "[390000/414113] Tokenized the captions.\n",
      "[391000/414113] Tokenized the captions.\n",
      "[392000/414113] Tokenized the captions.\n",
      "[393000/414113] Tokenized the captions.\n",
      "[394000/414113] Tokenized the captions.\n",
      "[395000/414113] Tokenized the captions.\n",
      "[396000/414113] Tokenized the captions.\n",
      "[397000/414113] Tokenized the captions.\n",
      "[398000/414113] Tokenized the captions.\n",
      "[399000/414113] Tokenized the captions.\n",
      "[400000/414113] Tokenized the captions.\n",
      "[401000/414113] Tokenized the captions.\n",
      "[402000/414113] Tokenized the captions.\n",
      "[403000/414113] Tokenized the captions.\n",
      "[404000/414113] Tokenized the captions.\n",
      "[405000/414113] Tokenized the captions.\n",
      "[406000/414113] Tokenized the captions.\n",
      "[407000/414113] Tokenized the captions.\n",
      "[408000/414113] Tokenized the captions.\n",
      "[409000/414113] Tokenized the captions.\n",
      "[410000/414113] Tokenized the captions.\n",
      "[411000/414113] Tokenized the captions.\n",
      "[412000/414113] Tokenized the captions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[413000/414113] Tokenized the captions.\n",
      "[414000/414113] Tokenized the captions.\n",
      "Total vocabulary size: 9956\n",
      "Saved the vocabulary wrapper to 'vo.pkl'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "def build_vocab(json, threshold):\n",
    "    \"\"\"Build a simple vocabulary wrapper.\"\"\"\n",
    "    coco = COCO(json)\n",
    "    counter = Counter()\n",
    "    ids = coco.anns.keys()\n",
    "    for i, id in enumerate(ids):\n",
    "        caption = str(coco.anns[id]['caption'])\n",
    "        tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "        counter.update(tokens)\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(\"[{}/{}] Tokenized the captions.\".format(i+1, len(ids)))\n",
    "\n",
    "    # If the word frequency is less than 'threshold', then the word is discarded.\n",
    "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
    "\n",
    "    # Create a vocab wrapper and add some special tokens.\n",
    "    vocab = Vocabulary()\n",
    "    vocab.add_word('<pad>')\n",
    "    vocab.add_word('<start>')\n",
    "    vocab.add_word('<end>')\n",
    "    vocab.add_word('<unk>')\n",
    "\n",
    "    # Add the words to the vocabulary.\n",
    "    for i, word in enumerate(words):\n",
    "        vocab.add_word(word)\n",
    "    return vocab,words\n",
    "\n",
    "caption_path = 'data/annotations/captions_train2014.json'\n",
    "vocab,words = build_vocab(json=caption_path, threshold=4)\n",
    "vocab_path = \"vo.pkl\"\n",
    "with open(vocab_path, 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "print(\"Total vocabulary size: {}\".format(len(vocab)))\n",
    "print(\"Saved the vocabulary wrapper to '{}'\".format(vocab_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in words:\n",
    "#     if len(i) ==1:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import get_loader \n",
    "import pickle\n",
    "from build_vocab import Vocabulary\n",
    "image_dir = 'data/resized2014'\n",
    "caption_path = 'annotations/captions_train2014.json'\n",
    "# vocab = ''\n",
    "batch_size ='128'\n",
    "vocab_path = 'vocab.pkl'\n",
    "transform = None\n",
    "def main():\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    data_loader = get_loader(image_dir, caption_path, vocab, \n",
    "                             transform, batch_size,\n",
    "                             shuffle=True, num_workers=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "batch_size should be a positive integer value, but got batch_size=128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-ab6e155938b7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     data_loader = get_loader(image_dir, caption_path, vocab, \n\u001b[1;32m     14\u001b[0m                              \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                              shuffle=True, num_workers=1) \n\u001b[0m",
      "\u001b[0;32m/datasets/home/home-03/91/891/snagesh/captioning_tutorial/pytorch-tutorial/tutorials/03-advanced/image_captioning/data_loader.py\u001b[0m in \u001b[0;36mget_loader\u001b[0;34m(root, json, vocab, transform, batch_size, shuffle, num_workers)\u001b[0m\n\u001b[1;32m    102\u001b[0m                                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                                               \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                                               collate_fn=collate_fn)\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# auto_collation without custom batch_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mbatch_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             raise ValueError(\"batch_size should be a positive integer value, \"\n\u001b[0;32m--> 190\u001b[0;31m                              \"but got batch_size={}\".format(batch_size))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             raise ValueError(\"drop_last should be a boolean value, but got \"\n",
      "\u001b[0;31mValueError\u001b[0m: batch_size should be a positive integer value, but got batch_size=128"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
